{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.73s)\n",
      "creating index...\n",
      "index created!\n",
      "[1000/414113] Tokenized the captions.\n",
      "[2000/414113] Tokenized the captions.\n",
      "[3000/414113] Tokenized the captions.\n",
      "[4000/414113] Tokenized the captions.\n",
      "[5000/414113] Tokenized the captions.\n",
      "[6000/414113] Tokenized the captions.\n",
      "[7000/414113] Tokenized the captions.\n",
      "[8000/414113] Tokenized the captions.\n",
      "[9000/414113] Tokenized the captions.\n",
      "[10000/414113] Tokenized the captions.\n",
      "[11000/414113] Tokenized the captions.\n",
      "[12000/414113] Tokenized the captions.\n",
      "[13000/414113] Tokenized the captions.\n",
      "[14000/414113] Tokenized the captions.\n",
      "[15000/414113] Tokenized the captions.\n",
      "[16000/414113] Tokenized the captions.\n",
      "[17000/414113] Tokenized the captions.\n",
      "[18000/414113] Tokenized the captions.\n",
      "[19000/414113] Tokenized the captions.\n",
      "[20000/414113] Tokenized the captions.\n",
      "[21000/414113] Tokenized the captions.\n",
      "[22000/414113] Tokenized the captions.\n",
      "[23000/414113] Tokenized the captions.\n",
      "[24000/414113] Tokenized the captions.\n",
      "[25000/414113] Tokenized the captions.\n",
      "[26000/414113] Tokenized the captions.\n",
      "[27000/414113] Tokenized the captions.\n",
      "[28000/414113] Tokenized the captions.\n",
      "[29000/414113] Tokenized the captions.\n",
      "[30000/414113] Tokenized the captions.\n",
      "[31000/414113] Tokenized the captions.\n",
      "[32000/414113] Tokenized the captions.\n",
      "[33000/414113] Tokenized the captions.\n",
      "[34000/414113] Tokenized the captions.\n",
      "[35000/414113] Tokenized the captions.\n",
      "[36000/414113] Tokenized the captions.\n",
      "[37000/414113] Tokenized the captions.\n",
      "[38000/414113] Tokenized the captions.\n",
      "[39000/414113] Tokenized the captions.\n",
      "[40000/414113] Tokenized the captions.\n",
      "[41000/414113] Tokenized the captions.\n",
      "[42000/414113] Tokenized the captions.\n",
      "[43000/414113] Tokenized the captions.\n",
      "[44000/414113] Tokenized the captions.\n",
      "[45000/414113] Tokenized the captions.\n",
      "[46000/414113] Tokenized the captions.\n",
      "[47000/414113] Tokenized the captions.\n",
      "[48000/414113] Tokenized the captions.\n",
      "[49000/414113] Tokenized the captions.\n",
      "[50000/414113] Tokenized the captions.\n",
      "[51000/414113] Tokenized the captions.\n",
      "[52000/414113] Tokenized the captions.\n",
      "[53000/414113] Tokenized the captions.\n",
      "[54000/414113] Tokenized the captions.\n",
      "[55000/414113] Tokenized the captions.\n",
      "[56000/414113] Tokenized the captions.\n",
      "[57000/414113] Tokenized the captions.\n",
      "[58000/414113] Tokenized the captions.\n",
      "[59000/414113] Tokenized the captions.\n",
      "[60000/414113] Tokenized the captions.\n",
      "[61000/414113] Tokenized the captions.\n",
      "[62000/414113] Tokenized the captions.\n",
      "[63000/414113] Tokenized the captions.\n",
      "[64000/414113] Tokenized the captions.\n",
      "[65000/414113] Tokenized the captions.\n",
      "[66000/414113] Tokenized the captions.\n",
      "[67000/414113] Tokenized the captions.\n",
      "[68000/414113] Tokenized the captions.\n",
      "[69000/414113] Tokenized the captions.\n",
      "[70000/414113] Tokenized the captions.\n",
      "[71000/414113] Tokenized the captions.\n",
      "[72000/414113] Tokenized the captions.\n",
      "[73000/414113] Tokenized the captions.\n",
      "[74000/414113] Tokenized the captions.\n",
      "[75000/414113] Tokenized the captions.\n",
      "[76000/414113] Tokenized the captions.\n",
      "[77000/414113] Tokenized the captions.\n",
      "[78000/414113] Tokenized the captions.\n",
      "[79000/414113] Tokenized the captions.\n",
      "[80000/414113] Tokenized the captions.\n",
      "[81000/414113] Tokenized the captions.\n",
      "[82000/414113] Tokenized the captions.\n",
      "[83000/414113] Tokenized the captions.\n",
      "[84000/414113] Tokenized the captions.\n",
      "[85000/414113] Tokenized the captions.\n",
      "[86000/414113] Tokenized the captions.\n",
      "[87000/414113] Tokenized the captions.\n",
      "[88000/414113] Tokenized the captions.\n",
      "[89000/414113] Tokenized the captions.\n",
      "[90000/414113] Tokenized the captions.\n",
      "[91000/414113] Tokenized the captions.\n",
      "[92000/414113] Tokenized the captions.\n",
      "[93000/414113] Tokenized the captions.\n",
      "[94000/414113] Tokenized the captions.\n",
      "[95000/414113] Tokenized the captions.\n",
      "[96000/414113] Tokenized the captions.\n",
      "[97000/414113] Tokenized the captions.\n",
      "[98000/414113] Tokenized the captions.\n",
      "[99000/414113] Tokenized the captions.\n",
      "[100000/414113] Tokenized the captions.\n",
      "[101000/414113] Tokenized the captions.\n",
      "[102000/414113] Tokenized the captions.\n",
      "[103000/414113] Tokenized the captions.\n",
      "[104000/414113] Tokenized the captions.\n",
      "[105000/414113] Tokenized the captions.\n",
      "[106000/414113] Tokenized the captions.\n",
      "[107000/414113] Tokenized the captions.\n",
      "[108000/414113] Tokenized the captions.\n",
      "[109000/414113] Tokenized the captions.\n",
      "[110000/414113] Tokenized the captions.\n",
      "[111000/414113] Tokenized the captions.\n",
      "[112000/414113] Tokenized the captions.\n",
      "[113000/414113] Tokenized the captions.\n",
      "[114000/414113] Tokenized the captions.\n",
      "[115000/414113] Tokenized the captions.\n",
      "[116000/414113] Tokenized the captions.\n",
      "[117000/414113] Tokenized the captions.\n",
      "[118000/414113] Tokenized the captions.\n",
      "[119000/414113] Tokenized the captions.\n",
      "[120000/414113] Tokenized the captions.\n",
      "[121000/414113] Tokenized the captions.\n",
      "[122000/414113] Tokenized the captions.\n",
      "[123000/414113] Tokenized the captions.\n",
      "[124000/414113] Tokenized the captions.\n",
      "[125000/414113] Tokenized the captions.\n",
      "[126000/414113] Tokenized the captions.\n",
      "[127000/414113] Tokenized the captions.\n",
      "[128000/414113] Tokenized the captions.\n",
      "[129000/414113] Tokenized the captions.\n",
      "[130000/414113] Tokenized the captions.\n",
      "[131000/414113] Tokenized the captions.\n",
      "[132000/414113] Tokenized the captions.\n",
      "[133000/414113] Tokenized the captions.\n",
      "[134000/414113] Tokenized the captions.\n",
      "[135000/414113] Tokenized the captions.\n",
      "[136000/414113] Tokenized the captions.\n",
      "[137000/414113] Tokenized the captions.\n",
      "[138000/414113] Tokenized the captions.\n",
      "[139000/414113] Tokenized the captions.\n",
      "[140000/414113] Tokenized the captions.\n",
      "[141000/414113] Tokenized the captions.\n",
      "[142000/414113] Tokenized the captions.\n",
      "[143000/414113] Tokenized the captions.\n",
      "[144000/414113] Tokenized the captions.\n",
      "[145000/414113] Tokenized the captions.\n",
      "[146000/414113] Tokenized the captions.\n",
      "[147000/414113] Tokenized the captions.\n",
      "[148000/414113] Tokenized the captions.\n",
      "[149000/414113] Tokenized the captions.\n",
      "[150000/414113] Tokenized the captions.\n",
      "[151000/414113] Tokenized the captions.\n",
      "[152000/414113] Tokenized the captions.\n",
      "[153000/414113] Tokenized the captions.\n",
      "[154000/414113] Tokenized the captions.\n",
      "[155000/414113] Tokenized the captions.\n",
      "[156000/414113] Tokenized the captions.\n",
      "[157000/414113] Tokenized the captions.\n",
      "[158000/414113] Tokenized the captions.\n",
      "[159000/414113] Tokenized the captions.\n",
      "[160000/414113] Tokenized the captions.\n",
      "[161000/414113] Tokenized the captions.\n",
      "[162000/414113] Tokenized the captions.\n",
      "[163000/414113] Tokenized the captions.\n",
      "[164000/414113] Tokenized the captions.\n",
      "[165000/414113] Tokenized the captions.\n",
      "[166000/414113] Tokenized the captions.\n",
      "[167000/414113] Tokenized the captions.\n",
      "[168000/414113] Tokenized the captions.\n",
      "[169000/414113] Tokenized the captions.\n",
      "[170000/414113] Tokenized the captions.\n",
      "[171000/414113] Tokenized the captions.\n",
      "[172000/414113] Tokenized the captions.\n",
      "[173000/414113] Tokenized the captions.\n",
      "[174000/414113] Tokenized the captions.\n",
      "[175000/414113] Tokenized the captions.\n",
      "[176000/414113] Tokenized the captions.\n",
      "[177000/414113] Tokenized the captions.\n",
      "[178000/414113] Tokenized the captions.\n",
      "[179000/414113] Tokenized the captions.\n",
      "[180000/414113] Tokenized the captions.\n",
      "[181000/414113] Tokenized the captions.\n",
      "[182000/414113] Tokenized the captions.\n",
      "[183000/414113] Tokenized the captions.\n",
      "[184000/414113] Tokenized the captions.\n",
      "[185000/414113] Tokenized the captions.\n",
      "[186000/414113] Tokenized the captions.\n",
      "[187000/414113] Tokenized the captions.\n",
      "[188000/414113] Tokenized the captions.\n",
      "[189000/414113] Tokenized the captions.\n",
      "[190000/414113] Tokenized the captions.\n",
      "[191000/414113] Tokenized the captions.\n",
      "[192000/414113] Tokenized the captions.\n",
      "[193000/414113] Tokenized the captions.\n",
      "[194000/414113] Tokenized the captions.\n",
      "[195000/414113] Tokenized the captions.\n",
      "[196000/414113] Tokenized the captions.\n",
      "[197000/414113] Tokenized the captions.\n",
      "[198000/414113] Tokenized the captions.\n",
      "[199000/414113] Tokenized the captions.\n",
      "[200000/414113] Tokenized the captions.\n",
      "[201000/414113] Tokenized the captions.\n",
      "[202000/414113] Tokenized the captions.\n",
      "[203000/414113] Tokenized the captions.\n",
      "[204000/414113] Tokenized the captions.\n",
      "[205000/414113] Tokenized the captions.\n",
      "[206000/414113] Tokenized the captions.\n",
      "[207000/414113] Tokenized the captions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208000/414113] Tokenized the captions.\n",
      "[209000/414113] Tokenized the captions.\n",
      "[210000/414113] Tokenized the captions.\n",
      "[211000/414113] Tokenized the captions.\n",
      "[212000/414113] Tokenized the captions.\n",
      "[213000/414113] Tokenized the captions.\n",
      "[214000/414113] Tokenized the captions.\n",
      "[215000/414113] Tokenized the captions.\n",
      "[216000/414113] Tokenized the captions.\n",
      "[217000/414113] Tokenized the captions.\n",
      "[218000/414113] Tokenized the captions.\n",
      "[219000/414113] Tokenized the captions.\n",
      "[220000/414113] Tokenized the captions.\n",
      "[221000/414113] Tokenized the captions.\n",
      "[222000/414113] Tokenized the captions.\n",
      "[223000/414113] Tokenized the captions.\n",
      "[224000/414113] Tokenized the captions.\n",
      "[225000/414113] Tokenized the captions.\n",
      "[226000/414113] Tokenized the captions.\n",
      "[227000/414113] Tokenized the captions.\n",
      "[228000/414113] Tokenized the captions.\n",
      "[229000/414113] Tokenized the captions.\n",
      "[230000/414113] Tokenized the captions.\n",
      "[231000/414113] Tokenized the captions.\n",
      "[232000/414113] Tokenized the captions.\n",
      "[233000/414113] Tokenized the captions.\n",
      "[234000/414113] Tokenized the captions.\n",
      "[235000/414113] Tokenized the captions.\n",
      "[236000/414113] Tokenized the captions.\n",
      "[237000/414113] Tokenized the captions.\n",
      "[238000/414113] Tokenized the captions.\n",
      "[239000/414113] Tokenized the captions.\n",
      "[240000/414113] Tokenized the captions.\n",
      "[241000/414113] Tokenized the captions.\n",
      "[242000/414113] Tokenized the captions.\n",
      "[243000/414113] Tokenized the captions.\n",
      "[244000/414113] Tokenized the captions.\n",
      "[245000/414113] Tokenized the captions.\n",
      "[246000/414113] Tokenized the captions.\n",
      "[247000/414113] Tokenized the captions.\n",
      "[248000/414113] Tokenized the captions.\n",
      "[249000/414113] Tokenized the captions.\n",
      "[250000/414113] Tokenized the captions.\n",
      "[251000/414113] Tokenized the captions.\n",
      "[252000/414113] Tokenized the captions.\n",
      "[253000/414113] Tokenized the captions.\n",
      "[254000/414113] Tokenized the captions.\n",
      "[255000/414113] Tokenized the captions.\n",
      "[256000/414113] Tokenized the captions.\n",
      "[257000/414113] Tokenized the captions.\n",
      "[258000/414113] Tokenized the captions.\n",
      "[259000/414113] Tokenized the captions.\n",
      "[260000/414113] Tokenized the captions.\n",
      "[261000/414113] Tokenized the captions.\n",
      "[262000/414113] Tokenized the captions.\n",
      "[263000/414113] Tokenized the captions.\n",
      "[264000/414113] Tokenized the captions.\n",
      "[265000/414113] Tokenized the captions.\n",
      "[266000/414113] Tokenized the captions.\n",
      "[267000/414113] Tokenized the captions.\n",
      "[268000/414113] Tokenized the captions.\n",
      "[269000/414113] Tokenized the captions.\n",
      "[270000/414113] Tokenized the captions.\n",
      "[271000/414113] Tokenized the captions.\n",
      "[272000/414113] Tokenized the captions.\n",
      "[273000/414113] Tokenized the captions.\n",
      "[274000/414113] Tokenized the captions.\n",
      "[275000/414113] Tokenized the captions.\n",
      "[276000/414113] Tokenized the captions.\n",
      "[277000/414113] Tokenized the captions.\n",
      "[278000/414113] Tokenized the captions.\n",
      "[279000/414113] Tokenized the captions.\n",
      "[280000/414113] Tokenized the captions.\n",
      "[281000/414113] Tokenized the captions.\n",
      "[282000/414113] Tokenized the captions.\n",
      "[283000/414113] Tokenized the captions.\n",
      "[284000/414113] Tokenized the captions.\n",
      "[285000/414113] Tokenized the captions.\n",
      "[286000/414113] Tokenized the captions.\n",
      "[287000/414113] Tokenized the captions.\n",
      "[288000/414113] Tokenized the captions.\n",
      "[289000/414113] Tokenized the captions.\n",
      "[290000/414113] Tokenized the captions.\n",
      "[291000/414113] Tokenized the captions.\n",
      "[292000/414113] Tokenized the captions.\n",
      "[293000/414113] Tokenized the captions.\n",
      "[294000/414113] Tokenized the captions.\n",
      "[295000/414113] Tokenized the captions.\n",
      "[296000/414113] Tokenized the captions.\n",
      "[297000/414113] Tokenized the captions.\n",
      "[298000/414113] Tokenized the captions.\n",
      "[299000/414113] Tokenized the captions.\n",
      "[300000/414113] Tokenized the captions.\n",
      "[301000/414113] Tokenized the captions.\n",
      "[302000/414113] Tokenized the captions.\n",
      "[303000/414113] Tokenized the captions.\n",
      "[304000/414113] Tokenized the captions.\n",
      "[305000/414113] Tokenized the captions.\n",
      "[306000/414113] Tokenized the captions.\n",
      "[307000/414113] Tokenized the captions.\n",
      "[308000/414113] Tokenized the captions.\n",
      "[309000/414113] Tokenized the captions.\n",
      "[310000/414113] Tokenized the captions.\n",
      "[311000/414113] Tokenized the captions.\n",
      "[312000/414113] Tokenized the captions.\n",
      "[313000/414113] Tokenized the captions.\n",
      "[314000/414113] Tokenized the captions.\n",
      "[315000/414113] Tokenized the captions.\n",
      "[316000/414113] Tokenized the captions.\n",
      "[317000/414113] Tokenized the captions.\n",
      "[318000/414113] Tokenized the captions.\n",
      "[319000/414113] Tokenized the captions.\n",
      "[320000/414113] Tokenized the captions.\n",
      "[321000/414113] Tokenized the captions.\n",
      "[322000/414113] Tokenized the captions.\n",
      "[323000/414113] Tokenized the captions.\n",
      "[324000/414113] Tokenized the captions.\n",
      "[325000/414113] Tokenized the captions.\n",
      "[326000/414113] Tokenized the captions.\n",
      "[327000/414113] Tokenized the captions.\n",
      "[328000/414113] Tokenized the captions.\n",
      "[329000/414113] Tokenized the captions.\n",
      "[330000/414113] Tokenized the captions.\n",
      "[331000/414113] Tokenized the captions.\n",
      "[332000/414113] Tokenized the captions.\n",
      "[333000/414113] Tokenized the captions.\n",
      "[334000/414113] Tokenized the captions.\n",
      "[335000/414113] Tokenized the captions.\n",
      "[336000/414113] Tokenized the captions.\n",
      "[337000/414113] Tokenized the captions.\n",
      "[338000/414113] Tokenized the captions.\n",
      "[339000/414113] Tokenized the captions.\n",
      "[340000/414113] Tokenized the captions.\n",
      "[341000/414113] Tokenized the captions.\n",
      "[342000/414113] Tokenized the captions.\n",
      "[343000/414113] Tokenized the captions.\n",
      "[344000/414113] Tokenized the captions.\n",
      "[345000/414113] Tokenized the captions.\n",
      "[346000/414113] Tokenized the captions.\n",
      "[347000/414113] Tokenized the captions.\n",
      "[348000/414113] Tokenized the captions.\n",
      "[349000/414113] Tokenized the captions.\n",
      "[350000/414113] Tokenized the captions.\n",
      "[351000/414113] Tokenized the captions.\n",
      "[352000/414113] Tokenized the captions.\n",
      "[353000/414113] Tokenized the captions.\n",
      "[354000/414113] Tokenized the captions.\n",
      "[355000/414113] Tokenized the captions.\n",
      "[356000/414113] Tokenized the captions.\n",
      "[357000/414113] Tokenized the captions.\n",
      "[358000/414113] Tokenized the captions.\n",
      "[359000/414113] Tokenized the captions.\n",
      "[360000/414113] Tokenized the captions.\n",
      "[361000/414113] Tokenized the captions.\n",
      "[362000/414113] Tokenized the captions.\n",
      "[363000/414113] Tokenized the captions.\n",
      "[364000/414113] Tokenized the captions.\n",
      "[365000/414113] Tokenized the captions.\n",
      "[366000/414113] Tokenized the captions.\n",
      "[367000/414113] Tokenized the captions.\n",
      "[368000/414113] Tokenized the captions.\n",
      "[369000/414113] Tokenized the captions.\n",
      "[370000/414113] Tokenized the captions.\n",
      "[371000/414113] Tokenized the captions.\n",
      "[372000/414113] Tokenized the captions.\n",
      "[373000/414113] Tokenized the captions.\n",
      "[374000/414113] Tokenized the captions.\n",
      "[375000/414113] Tokenized the captions.\n",
      "[376000/414113] Tokenized the captions.\n",
      "[377000/414113] Tokenized the captions.\n",
      "[378000/414113] Tokenized the captions.\n",
      "[379000/414113] Tokenized the captions.\n",
      "[380000/414113] Tokenized the captions.\n",
      "[381000/414113] Tokenized the captions.\n",
      "[382000/414113] Tokenized the captions.\n",
      "[383000/414113] Tokenized the captions.\n",
      "[384000/414113] Tokenized the captions.\n",
      "[385000/414113] Tokenized the captions.\n",
      "[386000/414113] Tokenized the captions.\n",
      "[387000/414113] Tokenized the captions.\n",
      "[388000/414113] Tokenized the captions.\n",
      "[389000/414113] Tokenized the captions.\n",
      "[390000/414113] Tokenized the captions.\n",
      "[391000/414113] Tokenized the captions.\n",
      "[392000/414113] Tokenized the captions.\n",
      "[393000/414113] Tokenized the captions.\n",
      "[394000/414113] Tokenized the captions.\n",
      "[395000/414113] Tokenized the captions.\n",
      "[396000/414113] Tokenized the captions.\n",
      "[397000/414113] Tokenized the captions.\n",
      "[398000/414113] Tokenized the captions.\n",
      "[399000/414113] Tokenized the captions.\n",
      "[400000/414113] Tokenized the captions.\n",
      "[401000/414113] Tokenized the captions.\n",
      "[402000/414113] Tokenized the captions.\n",
      "[403000/414113] Tokenized the captions.\n",
      "[404000/414113] Tokenized the captions.\n",
      "[405000/414113] Tokenized the captions.\n",
      "[406000/414113] Tokenized the captions.\n",
      "[407000/414113] Tokenized the captions.\n",
      "[408000/414113] Tokenized the captions.\n",
      "[409000/414113] Tokenized the captions.\n",
      "[410000/414113] Tokenized the captions.\n",
      "[411000/414113] Tokenized the captions.\n",
      "[412000/414113] Tokenized the captions.\n",
      "[413000/414113] Tokenized the captions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[414000/414113] Tokenized the captions.\n",
      "Total vocabulary size: 9956\n",
      "Saved the vocabulary wrapper to '../data/vocab.pkl'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('all') #use it if nltk gives a lookup error\n",
    "import pickle\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "caption_path = '../data/annotations/captions_train2014.json'\n",
    "vocab_path = '../data/vocab.pkl'\n",
    "threshold = 4\n",
    "\n",
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "def build_vocab(json, threshold):\n",
    "    \"\"\"Build a simple vocabulary wrapper.\"\"\"\n",
    "    coco = COCO(json)\n",
    "    counter = Counter()\n",
    "    ids = coco.anns.keys()\n",
    "    for i, id in enumerate(ids):\n",
    "        caption = str(coco.anns[id]['caption'])\n",
    "        tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
    "        counter.update(tokens)\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(\"[{}/{}] Tokenized the captions.\".format(i+1, len(ids)))\n",
    "\n",
    "    # If the word frequency is less than 'threshold', then the word is discarded.\n",
    "    words = [word for word, cnt in counter.items() if cnt >= threshold]\n",
    "\n",
    "    # Create a vocab wrapper and add some special tokens.\n",
    "    vocab = Vocabulary()\n",
    "    vocab.add_word('<pad>')\n",
    "    vocab.add_word('<start>')\n",
    "    vocab.add_word('<end>')\n",
    "    vocab.add_word('<unk>')\n",
    "\n",
    "    # Add the words to the vocabulary.\n",
    "    for i, word in enumerate(words):\n",
    "        vocab.add_word(word)\n",
    "    return vocab\n",
    "\n",
    "def main():\n",
    "    vocab = build_vocab(json=caption_path, threshold=threshold)\n",
    "    with open(vocab_path, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    print(\"Total vocabulary size: {}\".format(len(vocab)))\n",
    "    print(\"Saved the vocabulary wrapper to '{}'\".format(vocab_path))\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/82783] Resized the images and saved into '../data/resized2014/'.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bf6b4930e83c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mresize_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-bf6b4930e83c>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mresize_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-bf6b4930e83c>\u001b[0m in \u001b[0;36mresize_images\u001b[1;34m(image_dir, output_dir, size)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mnum_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r+b'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "image_dir = '../data/train2014/'\n",
    "output_dir = '../data/resized2014/'\n",
    "image_size = 256\n",
    "\n",
    "def resize_image(image, size):\n",
    "    \"\"\"Resize an image to the given size.\"\"\"\n",
    "    return image.resize(size, Image.ANTIALIAS)\n",
    "\n",
    "def resize_images(image_dir, output_dir, size):\n",
    "    \"\"\"Resize the images in 'image_dir' and save into 'output_dir'.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    images = os.listdir(image_dir)\n",
    "    num_images = len(images)\n",
    "    for i, image in enumerate(images):\n",
    "        with open(os.path.join(image_dir, image), 'r+b') as f:\n",
    "            with Image.open(f) as img:\n",
    "                img = resize_image(img, size)\n",
    "                img.save(os.path.join(output_dir, image), img.format)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"[{}/{}] Resized the images and saved into '{}'.\"\n",
    "                   .format(i+1, num_images, output_dir))\n",
    "\n",
    "def main():\n",
    "    resize_images(image_dir, output_dir, [image_size, image_size])\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        \"\"\"Load the pretrained ResNet-152 and replace top fc layer.\"\"\"\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        resnet = models.resnet152(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.linear = nn.Linear(resnet.fc.in_features, embed_size)\n",
    "        self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        \"\"\"Extract feature vectors from input images.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            features = self.resnet(images)\n",
    "        features = features.reshape(features.size(0), -1)\n",
    "        features = self.bn(self.linear(features))\n",
    "        return features\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers, max_seq_length=20):\n",
    "        \"\"\"Set the hyper-parameters and build the layers.\"\"\"\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.max_seg_length = max_seq_length\n",
    "        \n",
    "    def forward(self, features, captions, lengths):\n",
    "        \"\"\"Decode image feature vectors and generates captions.\"\"\"\n",
    "        embeddings = self.embed(captions)\n",
    "        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
    "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True) \n",
    "        hiddens, _ = self.lstm(packed)\n",
    "        outputs = self.linear(hiddens[0])\n",
    "        return outputs\n",
    "    \n",
    "    def sample(self, features, states=None):\n",
    "        \"\"\"Generate captions for given image features using greedy search.\"\"\"\n",
    "        sampled_ids = []\n",
    "        inputs = features.unsqueeze(1)\n",
    "        for i in range(self.max_seg_length):\n",
    "            hiddens, states = self.lstm(inputs, states)          # hiddens: (batch_size, 1, hidden_size)\n",
    "            outputs = self.linear(hiddens.squeeze(1))            # outputs:  (batch_size, vocab_size)\n",
    "            _, predicted = outputs.max(1)                        # predicted: (batch_size)\n",
    "            sampled_ids.append(predicted)\n",
    "            inputs = self.embed(predicted)                       # inputs: (batch_size, embed_size)\n",
    "            inputs = inputs.unsqueeze(1)                         # inputs: (batch_size, 1, embed_size)\n",
    "        sampled_ids = torch.stack(sampled_ids, 1)                # sampled_ids: (batch_size, max_seq_length)\n",
    "        return sampled_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "loading annotations into memory...\n",
      "Done (t=0.73s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch [0/1], Step [0/3236], Loss: 9.2094, Perplexity: 9990.1356\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8f334ecc47c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-8f334ecc47c8>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mtotal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;31m# Set mini-batch dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\data\\data_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2770\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2771\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "#torch.cuda.current_device()\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from data_loader import get_loader \n",
    "from build_vocab import Vocabulary\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchvision import transforms\n",
    "\n",
    "model_path = 'models/'\n",
    "crop_size = 224\n",
    "vocab_path = '../data/vocab.pkl'\n",
    "image_dir = '../data/resized2014'\n",
    "caption_path = '../data/annotations/captions_train2014.json'\n",
    "log_step = 10\n",
    "save_step = 1000\n",
    "\n",
    "# Model parameters\n",
    "embed_size = 256\n",
    "hidden_size = 521\n",
    "num_layers = 2 # 2 lstm layers\n",
    "num_epochs = 1\n",
    "batch_size = 128\n",
    "num_workers = 0 \n",
    "learning_rate = 0.001\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "def main():\n",
    "    # Create model directory\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    \n",
    "    # Image preprocessing, normalization for the pretrained resnet\n",
    "    transform = transforms.Compose([ \n",
    "        transforms.RandomCrop(crop_size),\n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                             (0.229, 0.224, 0.225))])\n",
    "    \n",
    "    # Load vocabulary wrapper\n",
    "    with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    \n",
    "    # Build data loader\n",
    "    data_loader = get_loader(image_dir, caption_path, vocab, \n",
    "                             transform, batch_size,\n",
    "                             shuffle=True, num_workers=num_workers) \n",
    "\n",
    "    # Build the models\n",
    "    encoder = EncoderCNN(embed_size).to(device)\n",
    "    decoder = DecoderRNN(embed_size, hidden_size, len(vocab), num_layers).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "    \n",
    "    # Train the models\n",
    "    total_step = len(data_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, captions, lengths) in enumerate(data_loader):\n",
    "            \n",
    "            # Set mini-batch dataset\n",
    "            images = images.to(device)\n",
    "            captions = captions.to(device)\n",
    "            targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
    "            \n",
    "            # Forward, backward and optimize\n",
    "            features = encoder(images)\n",
    "            outputs = decoder(features, captions, lengths)\n",
    "            loss = criterion(outputs, targets)\n",
    "            decoder.zero_grad()\n",
    "            encoder.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print log info\n",
    "            if i % log_step == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Perplexity: {:5.4f}'\n",
    "                      .format(epoch, num_epochs, i, total_step, loss.item(), np.exp(loss.item()))) \n",
    "                \n",
    "            # Save the model checkpoints\n",
    "            if (i+1) % save_step == 0:\n",
    "                torch.save(decoder.state_dict(), os.path.join(\n",
    "                    model_path, 'decoder-{}-{}.ckpt'.format(epoch+1, i+1)))\n",
    "                torch.save(encoder.state_dict(), os.path.join(\n",
    "                    model_path, 'encoder-{}-{}.ckpt'.format(epoch+1, i+1)))\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
