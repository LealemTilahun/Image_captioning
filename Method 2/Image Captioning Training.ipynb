{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import torch\n",
    "from scipy.misc import imread, imresize\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from random import seed, choice, sample\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models import Encoder, DecoderWithAttention\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import create_input_files\n",
    "# #Create input file hdf5\n",
    "# create_input_files(dataset='coco',\n",
    "#                    karpathy_json_path='../caption_datasets/dataset_coco.json',\n",
    "#                    image_folder='../images_data/',\n",
    "#                    captions_per_image=5,\n",
    "#                    min_word_freq=5,\n",
    "#                    output_folder='../output_train/',\n",
    "#                    max_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "writer = SummaryWriter(log_dir=\"tensorboard/\")\n",
    "\n",
    "# Data parameters\n",
    "data_folder = '../output_train/'  # folder with data files saved by create_input_files.py\n",
    "data_name = 'coco_5_cap_per_img_5_min_word_freq'  # base name shared by data files\n",
    "ckpt_name = 'coco_{}_epochs__{bleu:.4f}_bleu__{loss:.4f}_loss__{acc:.4f}_accu'  #ckpt name\n",
    "\n",
    "# Model parameters\n",
    "emb_dim = 512  # dimension of word embeddings\n",
    "attention_dim = 512  # dimension of attention linear layers\n",
    "decoder_dim = 512  # dimension of decoder RNN\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "\n",
    "# Training parameters\n",
    "start_epoch = 0\n",
    "epochs = 120  # number of epochs to train for (if early stopping is not triggered)\n",
    "epochs_since_improvement = 0  # keeps track of number of epochs since there's been an improvement in validation BLEU\n",
    "batch_size = 32\n",
    "workers = 1  # for data-loading; right now, only 1 works with h5py\n",
    "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
    "decoder_lr = 4e-4  # learning rate for decoder\n",
    "grad_clip = 5.  # clip gradients at an absolute value of\n",
    "alpha_c = 1.  # regularization parameter for 'doubly stochastic attention', as in the paper\n",
    "best_bleu4 = 0.  # BLEU-4 score right now\n",
    "print_freq = 100  # print training/validation stats every __ batches\n",
    "fine_tune_encoder = False  # fine-tune encoder?\n",
    "checkpoint = None  # path to checkpoint, None if none\n",
    "#checkpoint = \"checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Performs one epoch's training.\n",
    "\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param criterion: loss layer\n",
    "    :param encoder_optimizer: optimizer to update encoder's weights (if fine-tuning)\n",
    "    :param decoder_optimizer: optimizer to update decoder's weights\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "\n",
    "    decoder.train()  # train mode (dropout and batchnorm is used)\n",
    "    encoder.train()\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss (per word decoded)\n",
    "    top5accs = AverageMeter()  # top5 accuracy\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (imgs, caps, caplens) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to GPU, if available\n",
    "        imgs = imgs.to(device)\n",
    "        caps = caps.to(device)\n",
    "        caplens = caplens.to(device)\n",
    "\n",
    "        # Forward prop.\n",
    "        imgs = encoder(imgs)\n",
    "        scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "\n",
    "        # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "        targets = caps_sorted[:, 1:]\n",
    "\n",
    "        # Remove timesteps that we didn't decode at, or are pads\n",
    "        # pack_padded_sequence is an easy trick to do this\n",
    "        scores = pack_padded_sequence(scores, decode_lengths, batch_first=True).data\n",
    "        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Add doubly stochastic attention regularization\n",
    "        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "        # Back prop.\n",
    "        decoder_optimizer.zero_grad()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(decoder_optimizer, grad_clip)\n",
    "            if encoder_optimizer is not None:\n",
    "                clip_gradient(encoder_optimizer, grad_clip)\n",
    "\n",
    "        # Update weights\n",
    "        decoder_optimizer.step()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.step()\n",
    "\n",
    "        # Keep track of metrics\n",
    "        top5 = accuracy(scores, targets, 5)\n",
    "        losses.update(loss.item(), sum(decode_lengths))\n",
    "        top5accs.update(top5, sum(decode_lengths))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "\n",
    "        #write to tensorboard\n",
    "        writer.add_scalar('training_loss', losses.val, epoch)\n",
    "        writer.add_scalar('training_accuracy', top5accs.val, epoch)\n",
    "\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
    "                                                                          batch_time=batch_time,\n",
    "                                                                          data_time=data_time, loss=losses,\n",
    "                                                                          top5=top5accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, encoder, decoder, criterion):\n",
    "    \"\"\"\n",
    "    Performs one epoch's validation.\n",
    "\n",
    "    :param val_loader: DataLoader for validation data.\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param criterion: loss layer\n",
    "    :return: BLEU-4 score\n",
    "    \"\"\"\n",
    "    decoder.eval()  # eval mode (no dropout or batchnorm)\n",
    "    if encoder is not None:\n",
    "        encoder.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top5accs = AverageMeter()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    references = list()  # references (true captions) for calculating BLEU-4 score\n",
    "    hypotheses = list()  # hypotheses (predictions)\n",
    "\n",
    "    # explicitly disable gradient calculation to avoid CUDA memory error\n",
    "    # solves the issue #57\n",
    "    with torch.no_grad():\n",
    "        # Batches\n",
    "        for i, (imgs, caps, caplens, allcaps) in enumerate(val_loader):\n",
    "\n",
    "            # Move to device, if available\n",
    "            imgs = imgs.to(device)\n",
    "            caps = caps.to(device)\n",
    "            caplens = caplens.to(device)\n",
    "\n",
    "            # Forward prop.\n",
    "            if encoder is not None:\n",
    "                imgs = encoder(imgs)\n",
    "            scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "\n",
    "            # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "            targets = caps_sorted[:, 1:]\n",
    "\n",
    "            # Remove timesteps that we didn't decode at, or are pads\n",
    "            # pack_padded_sequence is an easy trick to do this\n",
    "            scores_copy = scores.clone()\n",
    "            scores= pack_padded_sequence(scores, decode_lengths, batch_first=True).data\n",
    "            targets = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            # Add doubly stochastic attention regularization\n",
    "            loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "            # Keep track of metrics\n",
    "            losses.update(loss.item(), sum(decode_lengths))\n",
    "            top5 = accuracy(scores, targets, 5)\n",
    "            top5accs.update(top5, sum(decode_lengths))\n",
    "            batch_time.update(time.time() - start)\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Validation: [{0}/{1}]\\t'\n",
    "                      'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})\\t'.format(i, len(val_loader), batch_time=batch_time,\n",
    "                                                                                loss=losses, top5=top5accs))\n",
    "\n",
    "            # Store references (true captions), and hypothesis (prediction) for each image\n",
    "            # If for n images, we have n hypotheses, and references a, b, c... for each image, we need -\n",
    "            # references = [[ref1a, ref1b, ref1c], [ref2a, ref2b], ...], hypotheses = [hyp1, hyp2, ...]\n",
    "\n",
    "            # References\n",
    "            allcaps = allcaps[sort_ind]  # because images were sorted in the decoder\n",
    "            for j in range(allcaps.shape[0]):\n",
    "                img_caps = allcaps[j].tolist()\n",
    "                img_captions = list(\n",
    "                    map(lambda c: [w for w in c if w not in {word_map['<start>'], word_map['<pad>']}],\n",
    "                        img_caps))  # remove <start> and pads\n",
    "                references.append(img_captions)\n",
    "\n",
    "            # Hypotheses\n",
    "            _, preds = torch.max(scores_copy, dim=2)\n",
    "            preds = preds.tolist()\n",
    "            temp_preds = list()\n",
    "            for j, p in enumerate(preds):\n",
    "                temp_preds.append(preds[j][:decode_lengths[j]])  # remove pads\n",
    "            preds = temp_preds\n",
    "            hypotheses.extend(preds)\n",
    "\n",
    "            assert len(references) == len(hypotheses)\n",
    "\n",
    "        # Calculate BLEU-4 scores\n",
    "        bleu4 = corpus_bleu(references, hypotheses)\n",
    "\n",
    "        print(\n",
    "            '\\n * LOSS - {loss.avg:.3f}, TOP-5 ACCURACY - {top5.avg:.3f}, BLEU-4 - {bleu}\\n'.format(\n",
    "                loss=losses,\n",
    "                top5=top5accs,\n",
    "                bleu=bleu4))\n",
    "\n",
    "        #write to tensorboard\n",
    "        writer.add_scalar('validation_loss', losses.val, epoch)\n",
    "        writer.add_scalar('validation_accuracy', top5accs.val, epoch)\n",
    "        writer.add_scalar('validation_bleu4', bleu4, epoch)\n",
    "\n",
    "        \n",
    "\n",
    "    return bleu4, losses.avg, top5accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /tmp/xdg-cache/torch/checkpoints/resnet152-b121ed2d.pth\n",
      "100%|██████████| 230M/230M [00:09<00:00, 24.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/17702]\tBatch Time 1.836 (1.836)\tData Load Time 0.362 (0.362)\tLoss 10.0520 (10.0520)\tTop-5 Accuracy 0.000 (0.000)\n",
      "Epoch: [0][100/17702]\tBatch Time 0.244 (0.266)\tData Load Time 0.000 (0.004)\tLoss 6.0038 (6.6746)\tTop-5 Accuracy 38.043 (34.473)\n",
      "Epoch: [0][200/17702]\tBatch Time 0.256 (0.260)\tData Load Time 0.000 (0.002)\tLoss 5.8753 (6.2542)\tTop-5 Accuracy 39.733 (37.475)\n",
      "Epoch: [0][300/17702]\tBatch Time 0.247 (0.260)\tData Load Time 0.001 (0.004)\tLoss 5.5189 (6.0203)\tTop-5 Accuracy 44.011 (39.801)\n",
      "Epoch: [0][400/17702]\tBatch Time 0.257 (0.259)\tData Load Time 0.000 (0.003)\tLoss 5.1371 (5.8373)\tTop-5 Accuracy 48.209 (41.928)\n",
      "Epoch: [0][500/17702]\tBatch Time 0.246 (0.257)\tData Load Time 0.000 (0.003)\tLoss 5.1928 (5.7003)\tTop-5 Accuracy 49.721 (43.551)\n",
      "Epoch: [0][600/17702]\tBatch Time 0.245 (0.256)\tData Load Time 0.000 (0.002)\tLoss 4.9300 (5.5874)\tTop-5 Accuracy 52.394 (44.978)\n",
      "Epoch: [0][700/17702]\tBatch Time 0.251 (0.256)\tData Load Time 0.000 (0.002)\tLoss 4.9594 (5.4900)\tTop-5 Accuracy 52.062 (46.235)\n",
      "Epoch: [0][800/17702]\tBatch Time 0.265 (0.255)\tData Load Time 0.001 (0.002)\tLoss 4.5580 (5.4044)\tTop-5 Accuracy 57.181 (47.367)\n",
      "Epoch: [0][900/17702]\tBatch Time 0.246 (0.255)\tData Load Time 0.001 (0.002)\tLoss 5.1945 (5.3317)\tTop-5 Accuracy 51.099 (48.303)\n",
      "Epoch: [0][1000/17702]\tBatch Time 0.250 (0.254)\tData Load Time 0.000 (0.002)\tLoss 4.1712 (5.2684)\tTop-5 Accuracy 57.895 (49.111)\n",
      "Epoch: [0][1100/17702]\tBatch Time 0.264 (0.254)\tData Load Time 0.000 (0.002)\tLoss 4.5059 (5.2138)\tTop-5 Accuracy 55.155 (49.819)\n",
      "Epoch: [0][1200/17702]\tBatch Time 0.242 (0.254)\tData Load Time 0.000 (0.001)\tLoss 4.6812 (5.1638)\tTop-5 Accuracy 57.224 (50.458)\n",
      "Epoch: [0][1300/17702]\tBatch Time 0.250 (0.254)\tData Load Time 0.001 (0.001)\tLoss 4.3057 (5.1152)\tTop-5 Accuracy 61.022 (51.080)\n",
      "Epoch: [0][1400/17702]\tBatch Time 0.241 (0.254)\tData Load Time 0.000 (0.001)\tLoss 4.7781 (5.0731)\tTop-5 Accuracy 55.989 (51.624)\n",
      "Epoch: [0][1500/17702]\tBatch Time 0.254 (0.254)\tData Load Time 0.000 (0.001)\tLoss 4.2418 (5.0352)\tTop-5 Accuracy 65.123 (52.119)\n",
      "Epoch: [0][1600/17702]\tBatch Time 0.254 (0.254)\tData Load Time 0.000 (0.001)\tLoss 4.6753 (4.9969)\tTop-5 Accuracy 55.676 (52.625)\n",
      "Epoch: [0][1700/17702]\tBatch Time 0.243 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.9636 (4.9628)\tTop-5 Accuracy 66.574 (53.049)\n",
      "Epoch: [0][1800/17702]\tBatch Time 0.242 (0.253)\tData Load Time 0.001 (0.001)\tLoss 4.5488 (4.9291)\tTop-5 Accuracy 62.254 (53.487)\n",
      "Epoch: [0][1900/17702]\tBatch Time 0.247 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.3404 (4.8988)\tTop-5 Accuracy 59.942 (53.867)\n",
      "Epoch: [0][2000/17702]\tBatch Time 0.245 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.5799 (4.8695)\tTop-5 Accuracy 59.673 (54.238)\n",
      "Epoch: [0][2100/17702]\tBatch Time 0.246 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.3034 (4.8440)\tTop-5 Accuracy 59.889 (54.563)\n",
      "Epoch: [0][2200/17702]\tBatch Time 0.258 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.4715 (4.8179)\tTop-5 Accuracy 59.424 (54.902)\n",
      "Epoch: [0][2300/17702]\tBatch Time 0.262 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.1175 (4.7941)\tTop-5 Accuracy 65.296 (55.199)\n",
      "Epoch: [0][2400/17702]\tBatch Time 0.249 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.3114 (4.7718)\tTop-5 Accuracy 60.215 (55.489)\n",
      "Epoch: [0][2500/17702]\tBatch Time 0.246 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.5386 (4.7497)\tTop-5 Accuracy 59.452 (55.780)\n",
      "Epoch: [0][2600/17702]\tBatch Time 0.239 (0.253)\tData Load Time 0.001 (0.001)\tLoss 4.4797 (4.7293)\tTop-5 Accuracy 58.187 (56.046)\n",
      "Epoch: [0][2700/17702]\tBatch Time 0.249 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0116 (4.7080)\tTop-5 Accuracy 65.782 (56.325)\n",
      "Epoch: [0][2800/17702]\tBatch Time 0.242 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.6590 (4.6901)\tTop-5 Accuracy 70.360 (56.554)\n",
      "Epoch: [0][2900/17702]\tBatch Time 0.260 (0.252)\tData Load Time 0.001 (0.001)\tLoss 4.3632 (4.6730)\tTop-5 Accuracy 59.621 (56.774)\n",
      "Epoch: [0][3000/17702]\tBatch Time 0.235 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0519 (4.6561)\tTop-5 Accuracy 64.545 (56.985)\n",
      "Epoch: [0][3100/17702]\tBatch Time 0.246 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0612 (4.6384)\tTop-5 Accuracy 64.986 (57.200)\n",
      "Epoch: [0][3200/17702]\tBatch Time 0.238 (0.252)\tData Load Time 0.001 (0.001)\tLoss 4.2217 (4.6230)\tTop-5 Accuracy 61.905 (57.398)\n",
      "Epoch: [0][3300/17702]\tBatch Time 0.245 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.4609 (4.6074)\tTop-5 Accuracy 74.085 (57.598)\n",
      "Epoch: [0][3400/17702]\tBatch Time 0.241 (0.252)\tData Load Time 0.001 (0.001)\tLoss 4.3076 (4.5927)\tTop-5 Accuracy 60.282 (57.786)\n",
      "Epoch: [0][3500/17702]\tBatch Time 0.253 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0940 (4.5803)\tTop-5 Accuracy 63.128 (57.948)\n",
      "Epoch: [0][3600/17702]\tBatch Time 0.243 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.2234 (4.5669)\tTop-5 Accuracy 62.842 (58.123)\n",
      "Epoch: [0][3700/17702]\tBatch Time 0.250 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0807 (4.5539)\tTop-5 Accuracy 66.856 (58.297)\n",
      "Epoch: [0][3800/17702]\tBatch Time 0.239 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0325 (4.5403)\tTop-5 Accuracy 66.851 (58.477)\n",
      "Epoch: [0][3900/17702]\tBatch Time 0.250 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.3930 (4.5282)\tTop-5 Accuracy 61.035 (58.638)\n",
      "Epoch: [0][4000/17702]\tBatch Time 0.245 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0694 (4.5159)\tTop-5 Accuracy 62.604 (58.799)\n",
      "Epoch: [0][4100/17702]\tBatch Time 0.249 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7812 (4.5043)\tTop-5 Accuracy 66.933 (58.948)\n",
      "Epoch: [0][4200/17702]\tBatch Time 0.241 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7605 (4.4929)\tTop-5 Accuracy 67.989 (59.097)\n",
      "Epoch: [0][4300/17702]\tBatch Time 0.246 (0.252)\tData Load Time 0.001 (0.001)\tLoss 4.0209 (4.4826)\tTop-5 Accuracy 63.380 (59.231)\n",
      "Epoch: [0][4400/17702]\tBatch Time 0.251 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.9617 (4.4716)\tTop-5 Accuracy 67.847 (59.372)\n",
      "Epoch: [0][4500/17702]\tBatch Time 0.245 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.2992 (4.4617)\tTop-5 Accuracy 61.173 (59.496)\n",
      "Epoch: [0][4600/17702]\tBatch Time 0.245 (0.252)\tData Load Time 0.001 (0.001)\tLoss 4.0279 (4.4517)\tTop-5 Accuracy 65.909 (59.623)\n",
      "Epoch: [0][4700/17702]\tBatch Time 0.252 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.3152 (4.4415)\tTop-5 Accuracy 63.342 (59.754)\n",
      "Epoch: [0][4800/17702]\tBatch Time 0.249 (0.252)\tData Load Time 0.001 (0.001)\tLoss 3.8773 (4.4314)\tTop-5 Accuracy 70.940 (59.882)\n",
      "Epoch: [0][4900/17702]\tBatch Time 0.244 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5963 (4.4218)\tTop-5 Accuracy 69.602 (60.005)\n",
      "Epoch: [0][5000/17702]\tBatch Time 0.241 (0.252)\tData Load Time 0.001 (0.001)\tLoss 3.8778 (4.4125)\tTop-5 Accuracy 66.944 (60.127)\n",
      "Epoch: [0][5100/17702]\tBatch Time 0.250 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.1554 (4.4035)\tTop-5 Accuracy 66.125 (60.236)\n",
      "Epoch: [0][5200/17702]\tBatch Time 0.242 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7588 (4.3953)\tTop-5 Accuracy 68.661 (60.345)\n",
      "Epoch: [0][5300/17702]\tBatch Time 0.245 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.8690 (4.3873)\tTop-5 Accuracy 67.313 (60.447)\n",
      "Epoch: [0][5400/17702]\tBatch Time 0.263 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0420 (4.3793)\tTop-5 Accuracy 65.934 (60.547)\n",
      "Epoch: [0][5500/17702]\tBatch Time 0.261 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7483 (4.3717)\tTop-5 Accuracy 68.542 (60.648)\n",
      "Epoch: [0][5600/17702]\tBatch Time 0.253 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5561 (4.3637)\tTop-5 Accuracy 71.667 (60.748)\n",
      "Epoch: [0][5700/17702]\tBatch Time 0.245 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.6840 (4.3554)\tTop-5 Accuracy 68.661 (60.852)\n",
      "Epoch: [0][5800/17702]\tBatch Time 0.300 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0216 (4.3473)\tTop-5 Accuracy 67.819 (60.957)\n",
      "Epoch: [0][5900/17702]\tBatch Time 0.248 (0.252)\tData Load Time 0.001 (0.001)\tLoss 4.0879 (4.3403)\tTop-5 Accuracy 65.217 (61.044)\n",
      "Epoch: [0][6000/17702]\tBatch Time 0.247 (0.252)\tData Load Time 0.001 (0.001)\tLoss 3.7677 (4.3332)\tTop-5 Accuracy 66.756 (61.136)\n",
      "Epoch: [0][6100/17702]\tBatch Time 0.271 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.9051 (4.3259)\tTop-5 Accuracy 69.388 (61.232)\n",
      "Epoch: [0][6200/17702]\tBatch Time 0.258 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.8584 (4.3189)\tTop-5 Accuracy 65.375 (61.322)\n",
      "Epoch: [0][6300/17702]\tBatch Time 0.247 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5347 (4.3118)\tTop-5 Accuracy 73.130 (61.414)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][6400/17702]\tBatch Time 0.241 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.6125 (4.3052)\tTop-5 Accuracy 67.429 (61.501)\n",
      "Epoch: [0][6500/17702]\tBatch Time 0.264 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.9032 (4.2983)\tTop-5 Accuracy 67.488 (61.589)\n",
      "Epoch: [0][6600/17702]\tBatch Time 0.244 (0.252)\tData Load Time 0.001 (0.001)\tLoss 3.7226 (4.2921)\tTop-5 Accuracy 68.144 (61.668)\n",
      "Epoch: [0][6700/17702]\tBatch Time 0.257 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.3581 (4.2856)\tTop-5 Accuracy 72.849 (61.750)\n",
      "Epoch: [0][6800/17702]\tBatch Time 0.283 (0.252)\tData Load Time 0.001 (0.001)\tLoss 4.1149 (4.2794)\tTop-5 Accuracy 64.491 (61.832)\n",
      "Epoch: [0][6900/17702]\tBatch Time 0.252 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7311 (4.2731)\tTop-5 Accuracy 67.213 (61.912)\n",
      "Epoch: [0][7000/17702]\tBatch Time 0.266 (0.252)\tData Load Time 0.001 (0.001)\tLoss 3.8839 (4.2667)\tTop-5 Accuracy 66.667 (61.996)\n",
      "Epoch: [0][7100/17702]\tBatch Time 0.249 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5835 (4.2609)\tTop-5 Accuracy 69.359 (62.071)\n",
      "Epoch: [0][7200/17702]\tBatch Time 0.275 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.1116 (4.2559)\tTop-5 Accuracy 67.018 (62.137)\n",
      "Epoch: [0][7300/17702]\tBatch Time 0.244 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.6077 (4.2501)\tTop-5 Accuracy 68.280 (62.212)\n",
      "Epoch: [0][7400/17702]\tBatch Time 0.243 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.8828 (4.2449)\tTop-5 Accuracy 67.359 (62.279)\n",
      "Epoch: [0][7500/17702]\tBatch Time 0.256 (0.252)\tData Load Time 0.003 (0.001)\tLoss 3.7828 (4.2396)\tTop-5 Accuracy 68.011 (62.351)\n",
      "Epoch: [0][7600/17702]\tBatch Time 0.246 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.8822 (4.2344)\tTop-5 Accuracy 67.209 (62.420)\n",
      "Epoch: [0][7700/17702]\tBatch Time 0.247 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5715 (4.2291)\tTop-5 Accuracy 69.688 (62.491)\n",
      "Epoch: [0][7800/17702]\tBatch Time 0.245 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5561 (4.2239)\tTop-5 Accuracy 69.252 (62.558)\n",
      "Epoch: [0][7900/17702]\tBatch Time 0.250 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.8258 (4.2187)\tTop-5 Accuracy 67.733 (62.622)\n",
      "Epoch: [0][8000/17702]\tBatch Time 0.250 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7239 (4.2139)\tTop-5 Accuracy 70.787 (62.680)\n",
      "Epoch: [0][8100/17702]\tBatch Time 0.246 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.9639 (4.2094)\tTop-5 Accuracy 68.611 (62.738)\n",
      "Epoch: [0][8200/17702]\tBatch Time 0.253 (0.252)\tData Load Time 0.000 (0.001)\tLoss 4.0898 (4.2047)\tTop-5 Accuracy 64.096 (62.798)\n",
      "Epoch: [0][8300/17702]\tBatch Time 0.259 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5787 (4.1997)\tTop-5 Accuracy 70.718 (62.864)\n",
      "Epoch: [0][8400/17702]\tBatch Time 0.250 (0.252)\tData Load Time 0.001 (0.001)\tLoss 3.6801 (4.1952)\tTop-5 Accuracy 70.083 (62.922)\n",
      "Epoch: [0][8500/17702]\tBatch Time 0.247 (0.252)\tData Load Time 0.001 (0.001)\tLoss 4.1508 (4.1907)\tTop-5 Accuracy 64.463 (62.979)\n",
      "Epoch: [0][8600/17702]\tBatch Time 0.261 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.9354 (4.1860)\tTop-5 Accuracy 65.553 (63.040)\n",
      "Epoch: [0][8700/17702]\tBatch Time 0.248 (0.252)\tData Load Time 0.001 (0.001)\tLoss 3.8693 (4.1815)\tTop-5 Accuracy 67.016 (63.100)\n",
      "Epoch: [0][8800/17702]\tBatch Time 0.254 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5605 (4.1774)\tTop-5 Accuracy 71.751 (63.156)\n",
      "Epoch: [0][8900/17702]\tBatch Time 0.248 (0.252)\tData Load Time 0.001 (0.001)\tLoss 3.6536 (4.1732)\tTop-5 Accuracy 68.661 (63.212)\n",
      "Epoch: [0][9000/17702]\tBatch Time 0.251 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.5175 (4.1687)\tTop-5 Accuracy 67.663 (63.271)\n",
      "Epoch: [0][9100/17702]\tBatch Time 0.250 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7921 (4.1643)\tTop-5 Accuracy 69.553 (63.329)\n",
      "Epoch: [0][9200/17702]\tBatch Time 0.238 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7635 (4.1600)\tTop-5 Accuracy 68.513 (63.386)\n",
      "Epoch: [0][9300/17702]\tBatch Time 0.317 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.9093 (4.1557)\tTop-5 Accuracy 66.577 (63.444)\n",
      "Epoch: [0][9400/17702]\tBatch Time 0.251 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.6311 (4.1511)\tTop-5 Accuracy 70.588 (63.502)\n",
      "Epoch: [0][9500/17702]\tBatch Time 0.276 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.6398 (4.1466)\tTop-5 Accuracy 67.027 (63.561)\n",
      "Epoch: [0][9600/17702]\tBatch Time 0.249 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.8429 (4.1426)\tTop-5 Accuracy 66.197 (63.614)\n",
      "Epoch: [0][9700/17702]\tBatch Time 0.249 (0.252)\tData Load Time 0.000 (0.001)\tLoss 3.7682 (4.1385)\tTop-5 Accuracy 70.270 (63.665)\n",
      "Epoch: [0][9800/17702]\tBatch Time 0.255 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6415 (4.1345)\tTop-5 Accuracy 73.404 (63.717)\n",
      "Epoch: [0][9900/17702]\tBatch Time 0.264 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7663 (4.1307)\tTop-5 Accuracy 66.759 (63.766)\n",
      "Epoch: [0][10000/17702]\tBatch Time 0.247 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.5574 (4.1267)\tTop-5 Accuracy 67.769 (63.816)\n",
      "Epoch: [0][10100/17702]\tBatch Time 0.248 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.5681 (4.1228)\tTop-5 Accuracy 72.067 (63.868)\n",
      "Epoch: [0][10200/17702]\tBatch Time 0.250 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7809 (4.1190)\tTop-5 Accuracy 68.661 (63.917)\n",
      "Epoch: [0][10300/17702]\tBatch Time 0.250 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7945 (4.1154)\tTop-5 Accuracy 67.385 (63.963)\n",
      "Epoch: [0][10400/17702]\tBatch Time 0.254 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7583 (4.1117)\tTop-5 Accuracy 68.085 (64.009)\n",
      "Epoch: [0][10500/17702]\tBatch Time 0.267 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6747 (4.1085)\tTop-5 Accuracy 71.154 (64.048)\n",
      "Epoch: [0][10600/17702]\tBatch Time 0.270 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.9287 (4.1052)\tTop-5 Accuracy 67.237 (64.090)\n",
      "Epoch: [0][10700/17702]\tBatch Time 0.254 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8775 (4.1018)\tTop-5 Accuracy 66.125 (64.133)\n",
      "Epoch: [0][10800/17702]\tBatch Time 0.241 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8619 (4.0988)\tTop-5 Accuracy 68.406 (64.171)\n",
      "Epoch: [0][10900/17702]\tBatch Time 0.266 (0.253)\tData Load Time 0.001 (0.001)\tLoss 3.7791 (4.0954)\tTop-5 Accuracy 69.271 (64.215)\n",
      "Epoch: [0][11000/17702]\tBatch Time 0.248 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8645 (4.0922)\tTop-5 Accuracy 68.956 (64.258)\n",
      "Epoch: [0][11100/17702]\tBatch Time 0.252 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8523 (4.0888)\tTop-5 Accuracy 62.050 (64.301)\n",
      "Epoch: [0][11200/17702]\tBatch Time 0.256 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6424 (4.0854)\tTop-5 Accuracy 68.519 (64.346)\n",
      "Epoch: [0][11300/17702]\tBatch Time 0.258 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.3875 (4.0820)\tTop-5 Accuracy 73.389 (64.389)\n",
      "Epoch: [0][11400/17702]\tBatch Time 0.245 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7149 (4.0787)\tTop-5 Accuracy 69.382 (64.433)\n",
      "Epoch: [0][11500/17702]\tBatch Time 0.255 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6331 (4.0756)\tTop-5 Accuracy 70.308 (64.471)\n",
      "Epoch: [0][11600/17702]\tBatch Time 0.250 (0.253)\tData Load Time 0.001 (0.001)\tLoss 3.5218 (4.0725)\tTop-5 Accuracy 73.130 (64.513)\n",
      "Epoch: [0][11700/17702]\tBatch Time 0.250 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.4637 (4.0691)\tTop-5 Accuracy 71.709 (64.557)\n",
      "Epoch: [0][11800/17702]\tBatch Time 0.241 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7387 (4.0662)\tTop-5 Accuracy 70.588 (64.597)\n",
      "Epoch: [0][11900/17702]\tBatch Time 0.249 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.3922 (4.0632)\tTop-5 Accuracy 73.977 (64.637)\n",
      "Epoch: [0][12000/17702]\tBatch Time 0.257 (0.253)\tData Load Time 0.001 (0.001)\tLoss 3.3625 (4.0603)\tTop-5 Accuracy 73.138 (64.674)\n",
      "Epoch: [0][12100/17702]\tBatch Time 0.253 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.9726 (4.0574)\tTop-5 Accuracy 66.757 (64.711)\n",
      "Epoch: [0][12200/17702]\tBatch Time 0.263 (0.253)\tData Load Time 0.001 (0.001)\tLoss 3.4778 (4.0547)\tTop-5 Accuracy 71.244 (64.748)\n",
      "Epoch: [0][12300/17702]\tBatch Time 0.254 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.9024 (4.0519)\tTop-5 Accuracy 67.617 (64.784)\n",
      "Epoch: [0][12400/17702]\tBatch Time 0.251 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.4781 (4.0491)\tTop-5 Accuracy 71.159 (64.819)\n",
      "Epoch: [0][12500/17702]\tBatch Time 0.292 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8190 (4.0461)\tTop-5 Accuracy 69.648 (64.858)\n",
      "Epoch: [0][12600/17702]\tBatch Time 0.245 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7638 (4.0434)\tTop-5 Accuracy 65.278 (64.894)\n",
      "Epoch: [0][12700/17702]\tBatch Time 0.239 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.4362 (4.0402)\tTop-5 Accuracy 72.650 (64.937)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][12800/17702]\tBatch Time 0.254 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.2495 (4.0377)\tTop-5 Accuracy 63.788 (64.970)\n",
      "Epoch: [0][12900/17702]\tBatch Time 0.252 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6302 (4.0349)\tTop-5 Accuracy 69.272 (65.006)\n",
      "Epoch: [0][13000/17702]\tBatch Time 0.251 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8809 (4.0322)\tTop-5 Accuracy 65.782 (65.040)\n",
      "Epoch: [0][13100/17702]\tBatch Time 0.255 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.9177 (4.0295)\tTop-5 Accuracy 68.533 (65.076)\n",
      "Epoch: [0][13200/17702]\tBatch Time 0.251 (0.253)\tData Load Time 0.001 (0.001)\tLoss 3.6724 (4.0269)\tTop-5 Accuracy 70.492 (65.111)\n",
      "Epoch: [0][13300/17702]\tBatch Time 0.258 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.5583 (4.0243)\tTop-5 Accuracy 68.966 (65.145)\n",
      "Epoch: [0][13400/17702]\tBatch Time 0.255 (0.253)\tData Load Time 0.001 (0.001)\tLoss 3.5800 (4.0214)\tTop-5 Accuracy 69.072 (65.182)\n",
      "Epoch: [0][13500/17702]\tBatch Time 0.249 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.5149 (4.0189)\tTop-5 Accuracy 72.386 (65.213)\n",
      "Epoch: [0][13600/17702]\tBatch Time 0.246 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6567 (4.0163)\tTop-5 Accuracy 71.467 (65.245)\n",
      "Epoch: [0][13700/17702]\tBatch Time 0.259 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6462 (4.0139)\tTop-5 Accuracy 70.588 (65.278)\n",
      "Epoch: [0][13800/17702]\tBatch Time 0.277 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6730 (4.0113)\tTop-5 Accuracy 67.473 (65.311)\n",
      "Epoch: [0][13900/17702]\tBatch Time 0.257 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6583 (4.0087)\tTop-5 Accuracy 71.350 (65.346)\n",
      "Epoch: [0][14000/17702]\tBatch Time 0.247 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.4971 (4.0064)\tTop-5 Accuracy 70.725 (65.376)\n",
      "Epoch: [0][14100/17702]\tBatch Time 0.300 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7014 (4.0038)\tTop-5 Accuracy 67.287 (65.409)\n",
      "Epoch: [0][14200/17702]\tBatch Time 0.259 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6856 (4.0015)\tTop-5 Accuracy 70.330 (65.439)\n",
      "Epoch: [0][14300/17702]\tBatch Time 0.261 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6361 (3.9991)\tTop-5 Accuracy 70.557 (65.471)\n",
      "Epoch: [0][14400/17702]\tBatch Time 0.251 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.5162 (3.9965)\tTop-5 Accuracy 72.603 (65.506)\n",
      "Epoch: [0][14500/17702]\tBatch Time 0.246 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6482 (3.9941)\tTop-5 Accuracy 71.105 (65.537)\n",
      "Epoch: [0][14600/17702]\tBatch Time 0.264 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.3226 (3.9916)\tTop-5 Accuracy 73.797 (65.571)\n",
      "Epoch: [0][14700/17702]\tBatch Time 0.249 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6209 (3.9894)\tTop-5 Accuracy 69.531 (65.599)\n",
      "Epoch: [0][14800/17702]\tBatch Time 0.295 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.0887 (3.9871)\tTop-5 Accuracy 66.334 (65.628)\n",
      "Epoch: [0][14900/17702]\tBatch Time 0.245 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.2585 (3.9848)\tTop-5 Accuracy 76.923 (65.658)\n",
      "Epoch: [0][15000/17702]\tBatch Time 0.257 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6912 (3.9825)\tTop-5 Accuracy 68.665 (65.689)\n",
      "Epoch: [0][15100/17702]\tBatch Time 0.255 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8885 (3.9803)\tTop-5 Accuracy 66.307 (65.717)\n",
      "Epoch: [0][15200/17702]\tBatch Time 0.250 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8213 (3.9781)\tTop-5 Accuracy 67.956 (65.745)\n",
      "Epoch: [0][15300/17702]\tBatch Time 0.236 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.9389 (3.9760)\tTop-5 Accuracy 66.272 (65.774)\n",
      "Epoch: [0][15400/17702]\tBatch Time 0.270 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.9456 (3.9738)\tTop-5 Accuracy 65.445 (65.802)\n",
      "Epoch: [0][15500/17702]\tBatch Time 0.269 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.5230 (3.9717)\tTop-5 Accuracy 73.107 (65.830)\n",
      "Epoch: [0][15600/17702]\tBatch Time 0.263 (0.253)\tData Load Time 0.000 (0.001)\tLoss 4.0854 (3.9696)\tTop-5 Accuracy 62.720 (65.857)\n",
      "Epoch: [0][15700/17702]\tBatch Time 0.254 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8094 (3.9677)\tTop-5 Accuracy 66.838 (65.881)\n",
      "Epoch: [0][15800/17702]\tBatch Time 0.244 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.3940 (3.9656)\tTop-5 Accuracy 77.233 (65.911)\n",
      "Epoch: [0][15900/17702]\tBatch Time 0.255 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7872 (3.9636)\tTop-5 Accuracy 68.937 (65.937)\n",
      "Epoch: [0][16000/17702]\tBatch Time 0.250 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7933 (3.9618)\tTop-5 Accuracy 69.474 (65.960)\n",
      "Epoch: [0][16100/17702]\tBatch Time 0.245 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7996 (3.9599)\tTop-5 Accuracy 68.889 (65.986)\n",
      "Epoch: [0][16200/17702]\tBatch Time 0.247 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6187 (3.9578)\tTop-5 Accuracy 71.350 (66.012)\n",
      "Epoch: [0][16300/17702]\tBatch Time 0.243 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.8368 (3.9559)\tTop-5 Accuracy 68.300 (66.037)\n",
      "Epoch: [0][16400/17702]\tBatch Time 0.248 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.4792 (3.9540)\tTop-5 Accuracy 73.371 (66.061)\n",
      "Epoch: [0][16500/17702]\tBatch Time 0.252 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.1945 (3.9520)\tTop-5 Accuracy 79.508 (66.086)\n",
      "Epoch: [0][16600/17702]\tBatch Time 0.270 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.4888 (3.9499)\tTop-5 Accuracy 72.414 (66.116)\n",
      "Epoch: [0][17000/17702]\tBatch Time 0.240 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.4014 (3.9421)\tTop-5 Accuracy 76.657 (66.214)\n",
      "Epoch: [0][17100/17702]\tBatch Time 0.256 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.4420 (3.9402)\tTop-5 Accuracy 73.442 (66.239)\n",
      "Epoch: [0][17200/17702]\tBatch Time 0.247 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.6539 (3.9383)\tTop-5 Accuracy 70.278 (66.263)\n",
      "Epoch: [0][17300/17702]\tBatch Time 0.256 (0.253)\tData Load Time 0.000 (0.001)\tLoss 3.7301 (3.9366)\tTop-5 Accuracy 68.564 (66.286)\n",
      "Epoch: [0][17400/17702]\tBatch Time 0.247 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.2091 (3.9348)\tTop-5 Accuracy 76.989 (66.310)\n",
      "Epoch: [0][17500/17702]\tBatch Time 0.240 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.3564 (3.9329)\tTop-5 Accuracy 73.775 (66.334)\n",
      "Epoch: [0][17600/17702]\tBatch Time 0.253 (0.254)\tData Load Time 0.001 (0.001)\tLoss 3.5082 (3.9308)\tTop-5 Accuracy 73.822 (66.361)\n",
      "Epoch: [0][17700/17702]\tBatch Time 0.273 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.6456 (3.9292)\tTop-5 Accuracy 69.832 (66.384)\n",
      "Validation: [0/782]\tBatch Time 0.644 (0.644)\tLoss 3.4338 (3.4338)\tTop-5 Accuracy 73.037 (73.037)\t\n",
      "Validation: [100/782]\tBatch Time 0.201 (0.203)\tLoss 3.1708 (3.4816)\tTop-5 Accuracy 78.571 (72.155)\t\n",
      "Validation: [200/782]\tBatch Time 0.194 (0.203)\tLoss 3.3721 (3.4688)\tTop-5 Accuracy 74.263 (72.256)\t\n",
      "Validation: [300/782]\tBatch Time 0.192 (0.200)\tLoss 3.6908 (3.4735)\tTop-5 Accuracy 70.027 (72.269)\t\n",
      "Validation: [400/782]\tBatch Time 0.195 (0.199)\tLoss 3.4375 (3.4762)\tTop-5 Accuracy 73.950 (72.196)\t\n",
      "Validation: [500/782]\tBatch Time 0.195 (0.198)\tLoss 3.4040 (3.4752)\tTop-5 Accuracy 74.095 (72.200)\t\n",
      "Validation: [600/782]\tBatch Time 0.193 (0.198)\tLoss 3.1069 (3.4760)\tTop-5 Accuracy 75.793 (72.211)\t\n",
      "Validation: [700/782]\tBatch Time 0.200 (0.198)\tLoss 3.2233 (3.4758)\tTop-5 Accuracy 76.648 (72.223)\t\n",
      "\n",
      " * LOSS - 3.472, TOP-5 ACCURACY - 72.253, BLEU-4 - 0.19440057001806563\n",
      "\n",
      "Saving model to file coco_0_epochs__0.1944_bleu__3.4724_loss__72.2525_accu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DecoderWithAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Softmax. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTMCell. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sigmoid. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/17702]\tBatch Time 0.828 (0.828)\tData Load Time 0.420 (0.420)\tLoss 3.5461 (3.5461)\tTop-5 Accuracy 71.504 (71.504)\n",
      "Epoch: [1][100/17702]\tBatch Time 0.244 (0.263)\tData Load Time 0.000 (0.005)\tLoss 3.5828 (3.5853)\tTop-5 Accuracy 69.859 (70.608)\n",
      "Epoch: [1][200/17702]\tBatch Time 0.252 (0.258)\tData Load Time 0.000 (0.003)\tLoss 3.5648 (3.5870)\tTop-5 Accuracy 71.186 (70.600)\n",
      "Epoch: [1][300/17702]\tBatch Time 0.279 (0.257)\tData Load Time 0.000 (0.002)\tLoss 3.7415 (3.5842)\tTop-5 Accuracy 67.847 (70.676)\n",
      "Epoch: [1][400/17702]\tBatch Time 0.262 (0.257)\tData Load Time 0.000 (0.001)\tLoss 3.5561 (3.5847)\tTop-5 Accuracy 70.213 (70.674)\n",
      "Epoch: [1][500/17702]\tBatch Time 0.249 (0.257)\tData Load Time 0.000 (0.001)\tLoss 3.9873 (3.5736)\tTop-5 Accuracy 67.655 (70.785)\n",
      "Epoch: [1][600/17702]\tBatch Time 0.247 (0.256)\tData Load Time 0.000 (0.001)\tLoss 3.3077 (3.5707)\tTop-5 Accuracy 71.429 (70.781)\n",
      "Epoch: [1][700/17702]\tBatch Time 0.245 (0.256)\tData Load Time 0.000 (0.001)\tLoss 3.7847 (3.5756)\tTop-5 Accuracy 65.193 (70.715)\n",
      "Epoch: [1][800/17702]\tBatch Time 0.245 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.1768 (3.5756)\tTop-5 Accuracy 76.694 (70.748)\n",
      "Epoch: [1][900/17702]\tBatch Time 0.245 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3358 (3.5710)\tTop-5 Accuracy 74.667 (70.821)\n",
      "Epoch: [1][1000/17702]\tBatch Time 0.246 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.7334 (3.5712)\tTop-5 Accuracy 68.391 (70.829)\n",
      "Epoch: [1][1100/17702]\tBatch Time 0.252 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3400 (3.5687)\tTop-5 Accuracy 74.185 (70.866)\n",
      "Epoch: [1][1200/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2508 (3.5645)\tTop-5 Accuracy 74.394 (70.924)\n",
      "Epoch: [1][1300/17702]\tBatch Time 0.245 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.4014 (3.5681)\tTop-5 Accuracy 71.625 (70.896)\n",
      "Epoch: [1][1400/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6510 (3.5675)\tTop-5 Accuracy 71.875 (70.900)\n",
      "Epoch: [1][1500/17702]\tBatch Time 0.254 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3704 (3.5677)\tTop-5 Accuracy 74.811 (70.903)\n",
      "Epoch: [1][1600/17702]\tBatch Time 0.247 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6368 (3.5682)\tTop-5 Accuracy 70.739 (70.895)\n",
      "Epoch: [1][1700/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3823 (3.5655)\tTop-5 Accuracy 73.475 (70.941)\n",
      "Epoch: [1][1800/17702]\tBatch Time 0.241 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5849 (3.5648)\tTop-5 Accuracy 72.394 (70.957)\n",
      "Epoch: [1][1900/17702]\tBatch Time 0.250 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.9217 (3.5633)\tTop-5 Accuracy 66.382 (70.984)\n",
      "Epoch: [1][2000/17702]\tBatch Time 0.245 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.3867 (3.5631)\tTop-5 Accuracy 70.655 (70.995)\n",
      "Epoch: [1][2400/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4001 (3.5622)\tTop-5 Accuracy 74.366 (71.014)\n",
      "Epoch: [1][2500/17702]\tBatch Time 0.266 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5886 (3.5613)\tTop-5 Accuracy 72.022 (71.029)\n",
      "Epoch: [1][2600/17702]\tBatch Time 0.278 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.7579 (3.5611)\tTop-5 Accuracy 68.700 (71.032)\n",
      "Epoch: [1][2700/17702]\tBatch Time 0.252 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5757 (3.5597)\tTop-5 Accuracy 70.538 (71.052)\n",
      "Epoch: [1][2800/17702]\tBatch Time 0.240 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3616 (3.5594)\tTop-5 Accuracy 74.138 (71.055)\n",
      "Epoch: [1][2900/17702]\tBatch Time 0.253 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.7566 (3.5594)\tTop-5 Accuracy 66.193 (71.057)\n",
      "Epoch: [1][3000/17702]\tBatch Time 0.241 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3775 (3.5587)\tTop-5 Accuracy 74.499 (71.074)\n",
      "Epoch: [1][3100/17702]\tBatch Time 0.238 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.3144 (3.5584)\tTop-5 Accuracy 74.493 (71.068)\n",
      "Epoch: [1][3200/17702]\tBatch Time 0.253 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.7335 (3.5582)\tTop-5 Accuracy 70.235 (71.080)\n",
      "Epoch: [1][3300/17702]\tBatch Time 0.254 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.6947 (3.5571)\tTop-5 Accuracy 69.086 (71.103)\n",
      "Epoch: [1][3400/17702]\tBatch Time 0.243 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5537 (3.5571)\tTop-5 Accuracy 70.538 (71.102)\n",
      "Epoch: [1][3500/17702]\tBatch Time 0.249 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.6822 (3.5568)\tTop-5 Accuracy 67.925 (71.107)\n",
      "Epoch: [1][3600/17702]\tBatch Time 0.239 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.4264 (3.5564)\tTop-5 Accuracy 72.941 (71.112)\n",
      "Epoch: [1][3700/17702]\tBatch Time 0.254 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3781 (3.5558)\tTop-5 Accuracy 71.229 (71.120)\n",
      "Epoch: [1][3800/17702]\tBatch Time 0.258 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.1395 (3.5552)\tTop-5 Accuracy 75.676 (71.130)\n",
      "Epoch: [1][3900/17702]\tBatch Time 0.269 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.6199 (3.5539)\tTop-5 Accuracy 70.300 (71.147)\n",
      "Epoch: [1][4000/17702]\tBatch Time 0.250 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.5853 (3.5534)\tTop-5 Accuracy 73.130 (71.151)\n",
      "Epoch: [1][4100/17702]\tBatch Time 0.245 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.6388 (3.5533)\tTop-5 Accuracy 71.031 (71.151)\n",
      "Epoch: [1][4200/17702]\tBatch Time 0.249 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.3052 (3.5525)\tTop-5 Accuracy 75.000 (71.161)\n",
      "Epoch: [1][4300/17702]\tBatch Time 0.263 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.4442 (3.5514)\tTop-5 Accuracy 73.421 (71.177)\n",
      "Epoch: [1][4400/17702]\tBatch Time 0.250 (0.254)\tData Load Time 0.000 (0.001)\tLoss 3.6249 (3.5513)\tTop-5 Accuracy 71.229 (71.183)\n",
      "Epoch: [1][4800/17702]\tBatch Time 0.253 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4575 (3.5511)\tTop-5 Accuracy 68.306 (71.188)\n",
      "Epoch: [1][4900/17702]\tBatch Time 0.263 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4765 (3.5511)\tTop-5 Accuracy 71.582 (71.193)\n",
      "Epoch: [1][5000/17702]\tBatch Time 0.256 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4095 (3.5511)\tTop-5 Accuracy 73.228 (71.190)\n",
      "Epoch: [1][5100/17702]\tBatch Time 0.251 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.4769 (3.5501)\tTop-5 Accuracy 71.835 (71.203)\n",
      "Epoch: [1][5200/17702]\tBatch Time 0.282 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5706 (3.5492)\tTop-5 Accuracy 71.814 (71.219)\n",
      "Epoch: [1][5300/17702]\tBatch Time 0.250 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4733 (3.5483)\tTop-5 Accuracy 72.973 (71.232)\n",
      "Epoch: [1][5400/17702]\tBatch Time 0.267 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.6002 (3.5483)\tTop-5 Accuracy 69.761 (71.229)\n",
      "Epoch: [1][5500/17702]\tBatch Time 0.244 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2588 (3.5481)\tTop-5 Accuracy 76.338 (71.234)\n",
      "Epoch: [1][5600/17702]\tBatch Time 0.268 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6700 (3.5481)\tTop-5 Accuracy 68.947 (71.237)\n",
      "Epoch: [1][5700/17702]\tBatch Time 0.264 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4744 (3.5480)\tTop-5 Accuracy 71.046 (71.240)\n",
      "Epoch: [1][5800/17702]\tBatch Time 0.262 (0.255)\tData Load Time 0.000 (0.000)\tLoss 3.3043 (3.5474)\tTop-5 Accuracy 74.413 (71.242)\n",
      "Epoch: [1][5900/17702]\tBatch Time 0.266 (0.255)\tData Load Time 0.000 (0.000)\tLoss 3.4554 (3.5466)\tTop-5 Accuracy 72.654 (71.252)\n",
      "Epoch: [1][6000/17702]\tBatch Time 0.281 (0.255)\tData Load Time 0.000 (0.000)\tLoss 3.8607 (3.5461)\tTop-5 Accuracy 67.131 (71.260)\n",
      "Epoch: [1][6100/17702]\tBatch Time 0.250 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6798 (3.5460)\tTop-5 Accuracy 71.311 (71.261)\n",
      "Epoch: [1][6200/17702]\tBatch Time 0.244 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2506 (3.5459)\tTop-5 Accuracy 74.656 (71.263)\n",
      "Epoch: [1][6300/17702]\tBatch Time 0.262 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.6824 (3.5454)\tTop-5 Accuracy 67.467 (71.271)\n",
      "Epoch: [1][6400/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5366 (3.5447)\tTop-5 Accuracy 72.826 (71.279)\n",
      "Epoch: [1][6500/17702]\tBatch Time 0.259 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3011 (3.5446)\tTop-5 Accuracy 75.556 (71.283)\n",
      "Epoch: [1][6600/17702]\tBatch Time 0.250 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4398 (3.5444)\tTop-5 Accuracy 72.394 (71.286)\n",
      "Epoch: [1][6700/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5046 (3.5440)\tTop-5 Accuracy 71.751 (71.291)\n",
      "Epoch: [1][6800/17702]\tBatch Time 0.255 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6580 (3.5437)\tTop-5 Accuracy 71.698 (71.298)\n",
      "Epoch: [1][6900/17702]\tBatch Time 0.260 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.7430 (3.5440)\tTop-5 Accuracy 69.251 (71.293)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][7000/17702]\tBatch Time 0.245 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.5590 (3.5433)\tTop-5 Accuracy 69.399 (71.302)\n",
      "Epoch: [1][7100/17702]\tBatch Time 0.260 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6193 (3.5434)\tTop-5 Accuracy 71.540 (71.300)\n",
      "Epoch: [1][7200/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.7979 (3.5428)\tTop-5 Accuracy 69.741 (71.306)\n",
      "Epoch: [1][7300/17702]\tBatch Time 0.278 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.8981 (3.5424)\tTop-5 Accuracy 66.491 (71.313)\n",
      "Epoch: [1][7400/17702]\tBatch Time 0.247 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4411 (3.5425)\tTop-5 Accuracy 74.521 (71.313)\n",
      "Epoch: [1][7500/17702]\tBatch Time 0.261 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.9373 (3.5423)\tTop-5 Accuracy 61.917 (71.319)\n",
      "Epoch: [1][7600/17702]\tBatch Time 0.254 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4290 (3.5421)\tTop-5 Accuracy 74.242 (71.323)\n",
      "Epoch: [1][7700/17702]\tBatch Time 0.258 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6273 (3.5418)\tTop-5 Accuracy 73.889 (71.329)\n",
      "Epoch: [1][7800/17702]\tBatch Time 0.251 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3468 (3.5415)\tTop-5 Accuracy 74.212 (71.335)\n",
      "Epoch: [1][7900/17702]\tBatch Time 0.239 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5116 (3.5413)\tTop-5 Accuracy 70.118 (71.339)\n",
      "Epoch: [1][8000/17702]\tBatch Time 0.238 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4394 (3.5409)\tTop-5 Accuracy 73.433 (71.343)\n",
      "Epoch: [1][8100/17702]\tBatch Time 0.257 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2492 (3.5406)\tTop-5 Accuracy 76.546 (71.351)\n",
      "Epoch: [1][8200/17702]\tBatch Time 0.246 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2020 (3.5403)\tTop-5 Accuracy 75.630 (71.357)\n",
      "Epoch: [1][8300/17702]\tBatch Time 0.249 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3305 (3.5398)\tTop-5 Accuracy 76.423 (71.367)\n",
      "Epoch: [1][8400/17702]\tBatch Time 0.247 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.3763 (3.5393)\tTop-5 Accuracy 74.586 (71.376)\n",
      "Epoch: [1][8500/17702]\tBatch Time 0.261 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5007 (3.5389)\tTop-5 Accuracy 72.296 (71.381)\n",
      "Epoch: [1][8600/17702]\tBatch Time 0.246 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.0413 (3.5383)\tTop-5 Accuracy 80.466 (71.390)\n",
      "Epoch: [1][8700/17702]\tBatch Time 0.293 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3542 (3.5381)\tTop-5 Accuracy 73.333 (71.392)\n",
      "Epoch: [1][8800/17702]\tBatch Time 0.254 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5815 (3.5378)\tTop-5 Accuracy 69.713 (71.393)\n",
      "Epoch: [1][8900/17702]\tBatch Time 0.243 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2278 (3.5378)\tTop-5 Accuracy 76.338 (71.398)\n",
      "Epoch: [1][9000/17702]\tBatch Time 0.260 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.7757 (3.5371)\tTop-5 Accuracy 67.380 (71.409)\n",
      "Epoch: [1][9100/17702]\tBatch Time 0.253 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3702 (3.5366)\tTop-5 Accuracy 72.973 (71.418)\n",
      "Epoch: [1][9200/17702]\tBatch Time 0.269 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5693 (3.5361)\tTop-5 Accuracy 71.930 (71.423)\n",
      "Epoch: [1][9300/17702]\tBatch Time 0.249 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6586 (3.5359)\tTop-5 Accuracy 69.916 (71.424)\n",
      "Epoch: [1][9400/17702]\tBatch Time 0.242 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.8463 (3.5351)\tTop-5 Accuracy 65.698 (71.433)\n",
      "Epoch: [1][9500/17702]\tBatch Time 0.282 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2442 (3.5348)\tTop-5 Accuracy 73.684 (71.440)\n",
      "Epoch: [1][9600/17702]\tBatch Time 0.240 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2624 (3.5345)\tTop-5 Accuracy 74.859 (71.445)\n",
      "Epoch: [1][9700/17702]\tBatch Time 0.243 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5612 (3.5343)\tTop-5 Accuracy 72.012 (71.449)\n",
      "Epoch: [1][9800/17702]\tBatch Time 0.264 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4605 (3.5338)\tTop-5 Accuracy 73.387 (71.456)\n",
      "Epoch: [1][9900/17702]\tBatch Time 0.242 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.8366 (3.5336)\tTop-5 Accuracy 69.679 (71.459)\n",
      "Epoch: [1][10000/17702]\tBatch Time 0.262 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6470 (3.5335)\tTop-5 Accuracy 69.444 (71.461)\n",
      "Epoch: [1][10100/17702]\tBatch Time 0.261 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6905 (3.5332)\tTop-5 Accuracy 67.120 (71.466)\n",
      "Epoch: [1][10200/17702]\tBatch Time 0.274 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.3009 (3.5328)\tTop-5 Accuracy 75.381 (71.473)\n",
      "Epoch: [1][10300/17702]\tBatch Time 0.246 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.0876 (3.5324)\tTop-5 Accuracy 79.670 (71.479)\n",
      "Epoch: [1][10400/17702]\tBatch Time 0.261 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.5468 (3.5318)\tTop-5 Accuracy 73.569 (71.489)\n",
      "Epoch: [1][10500/17702]\tBatch Time 0.245 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.7635 (3.5318)\tTop-5 Accuracy 69.146 (71.490)\n",
      "Epoch: [1][10600/17702]\tBatch Time 0.258 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6055 (3.5315)\tTop-5 Accuracy 69.890 (71.494)\n",
      "Epoch: [1][10700/17702]\tBatch Time 0.266 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.4596 (3.5310)\tTop-5 Accuracy 70.619 (71.499)\n",
      "Epoch: [1][10800/17702]\tBatch Time 0.263 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3920 (3.5307)\tTop-5 Accuracy 74.185 (71.504)\n",
      "Epoch: [1][10900/17702]\tBatch Time 0.242 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3953 (3.5304)\tTop-5 Accuracy 75.637 (71.508)\n",
      "Epoch: [1][11000/17702]\tBatch Time 0.257 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.3438 (3.5303)\tTop-5 Accuracy 73.210 (71.512)\n",
      "Epoch: [1][11100/17702]\tBatch Time 0.261 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4341 (3.5298)\tTop-5 Accuracy 72.432 (71.521)\n",
      "Epoch: [1][11200/17702]\tBatch Time 0.243 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.3674 (3.5293)\tTop-5 Accuracy 75.967 (71.529)\n",
      "Epoch: [1][11300/17702]\tBatch Time 0.240 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.0926 (3.5288)\tTop-5 Accuracy 77.971 (71.536)\n",
      "Epoch: [1][11400/17702]\tBatch Time 0.249 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.7688 (3.5284)\tTop-5 Accuracy 67.222 (71.541)\n",
      "Epoch: [1][11500/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4443 (3.5282)\tTop-5 Accuracy 71.053 (71.546)\n",
      "Epoch: [1][11600/17702]\tBatch Time 0.266 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2918 (3.5280)\tTop-5 Accuracy 76.068 (71.549)\n",
      "Epoch: [1][11700/17702]\tBatch Time 0.253 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.4719 (3.5279)\tTop-5 Accuracy 72.527 (71.551)\n",
      "Epoch: [1][11800/17702]\tBatch Time 0.238 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.6534 (3.5277)\tTop-5 Accuracy 71.053 (71.556)\n",
      "Epoch: [1][11900/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2363 (3.5275)\tTop-5 Accuracy 74.722 (71.560)\n",
      "Epoch: [1][12000/17702]\tBatch Time 0.248 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.5775 (3.5271)\tTop-5 Accuracy 72.404 (71.568)\n",
      "Epoch: [1][12100/17702]\tBatch Time 0.262 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5163 (3.5268)\tTop-5 Accuracy 71.011 (71.571)\n",
      "Epoch: [1][12200/17702]\tBatch Time 0.250 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5080 (3.5267)\tTop-5 Accuracy 71.667 (71.573)\n",
      "Epoch: [1][12300/17702]\tBatch Time 0.260 (0.255)\tData Load Time 0.001 (0.001)\tLoss 3.3759 (3.5265)\tTop-5 Accuracy 73.077 (71.577)\n",
      "Epoch: [1][12400/17702]\tBatch Time 0.258 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.2448 (3.5262)\tTop-5 Accuracy 74.474 (71.581)\n",
      "Epoch: [1][12500/17702]\tBatch Time 0.247 (0.255)\tData Load Time 0.000 (0.001)\tLoss 3.5961 (3.5258)\tTop-5 Accuracy 71.314 (71.589)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training and validation.\n",
    "\"\"\"\n",
    "\n",
    "global best_bleu4, epochs_since_improvement, checkpoint, start_epoch, fine_tune_encoder, data_name, word_map\n",
    "\n",
    "# Read word map\n",
    "word_map_file = os.path.join(data_folder, 'WORDMAP_' + data_name + '.json')\n",
    "with open(word_map_file, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "\n",
    "# Initialize / load checkpoint\n",
    "if checkpoint is None:\n",
    "\n",
    "    emb_dim=100 #remove if not usiong pretrained model\n",
    "    decoder = DecoderWithAttention(attention_dim=attention_dim,\n",
    "                                   embed_dim=emb_dim,\n",
    "                                   decoder_dim=decoder_dim,\n",
    "                                   vocab_size=len(word_map),\n",
    "                                   dropout=dropout)\n",
    "    pretrained_embeddings = decoder.create_pretrained_embedding_matrix(word_map)\n",
    "    decoder.load_pretrained_embeddings(\n",
    "        pretrained_embeddings)  # pretrained_embeddings should be of dimensions (len(word_map), emb_dim)\n",
    "    decoder.fine_tune_embeddings(True)\n",
    "\n",
    "    decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "                                         lr=decoder_lr)\n",
    "    encoder = Encoder()\n",
    "    encoder.fine_tune(fine_tune_encoder)\n",
    "    encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                         lr=encoder_lr) if fine_tune_encoder else None\n",
    "\n",
    "else:\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
    "    best_bleu4 = checkpoint['bleu-4']\n",
    "    decoder = checkpoint['decoder']\n",
    "    decoder_optimizer = checkpoint['decoder_optimizer']\n",
    "    encoder = checkpoint['encoder']\n",
    "    encoder_optimizer = checkpoint['encoder_optimizer']\n",
    "    if fine_tune_encoder is True and encoder_optimizer is None:\n",
    "        encoder.fine_tune(fine_tune_encoder)\n",
    "        encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                             lr=encoder_lr)\n",
    "\n",
    "# Move to GPU, if available\n",
    "decoder = decoder.to(device)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Custom dataloaders\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'VAL', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "\n",
    "# Epochs\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "    if epochs_since_improvement == 20:\n",
    "        break\n",
    "    if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "        adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "        if fine_tune_encoder:\n",
    "            adjust_learning_rate(encoder_optimizer, 0.8)\n",
    "\n",
    "    # One epoch's training\n",
    "    train(train_loader=train_loader,\n",
    "          encoder=encoder,\n",
    "          decoder=decoder,\n",
    "          criterion=criterion,\n",
    "          encoder_optimizer=encoder_optimizer,\n",
    "          decoder_optimizer=decoder_optimizer,\n",
    "          epoch=epoch)\n",
    "\n",
    "    # One epoch's validation\n",
    "    recent_bleu4, val_loss_avg, val_accu_avg = validate(val_loader=val_loader,\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            criterion=criterion)\n",
    "\n",
    "    # Check if there was an improvement\n",
    "    is_best = recent_bleu4 > best_bleu4\n",
    "    best_bleu4 = max(recent_bleu4, best_bleu4)\n",
    "    if not is_best:\n",
    "        epochs_since_improvement += 1\n",
    "        print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
    "    else:\n",
    "        epochs_since_improvement = 0\n",
    "\n",
    "    # Save checkpoint\n",
    "    print(\"Saving model to file\",ckpt_name.format(epoch, bleu=recent_bleu4, loss=val_loss_avg, acc=val_accu_avg))\n",
    "    save_checkpoint(ckpt_name.format(epoch, bleu=recent_bleu4, loss=val_loss_avg, acc=val_accu_avg), \n",
    "                    epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer,\n",
    "                    decoder_optimizer, recent_bleu4, is_best)\n",
    "\n",
    "#close tensorboard writer\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
